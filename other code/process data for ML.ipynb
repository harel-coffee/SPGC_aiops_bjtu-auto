{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a403e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "data_path = r'.'\n",
    "test_path = 'test600'\n",
    "train_path = 'train'\n",
    "\n",
    "label_path = r'.'\n",
    "train_label_file = 'train_label.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a4dce",
   "metadata": {},
   "source": [
    "## process data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dde1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature process\n",
    "def feature60_process(s):\n",
    "    if isinstance(s,str):\n",
    "        s = eval(s.replace(';',','))\n",
    "        s = round(np.mean(s), 2)\n",
    "    return s\n",
    "\n",
    "def feature20_edge_count(feature20_series):\n",
    "    edge_list = [0,1,6,7,8,9,14,15,16,17,22,23,24,25,30,31]\n",
    "    feature20_edge_count = 0\n",
    "    for num in feature20_series:\n",
    "        if not np.isnan(num) and num in edge_list:\n",
    "            feature20_edge_count +=1\n",
    "    if feature20_series.isnull().all() : feature20_edge_count = np.nan\n",
    "    return feature20_edge_count\n",
    "    \n",
    "def feature20_distance_count(feature20_series):\n",
    "    feature20_series.dropna(inplace=True)\n",
    "    coordinate = []\n",
    "    for m in feature20_series:\n",
    "        coordinate.append((m-8*(m//8), m//8))\n",
    "    distance = 0\n",
    "    for a in coordinate:\n",
    "        for b in coordinate:\n",
    "            distance = distance + ((a[0]-b[0])**2 + (a[1]-b[1])**2)**0.5\n",
    "    return distance \n",
    "\n",
    "def featureXY_process(featureXY_series):\n",
    "    featureY_list = ['feature28','feature36','feature44','feature52']\n",
    "    featureX_list = ['feature61','feature69','feature77','feature85']\n",
    "    featureX = pd.DataFrame()\n",
    "    featureY = pd.DataFrame()\n",
    "    for featureX_name in featureX_list:\n",
    "        featureX = featureX.append(featureXY_series.loc[featureXY_series.index.str.contains(featureX_name)])\n",
    "    for featureY_name in featureY_list:\n",
    "        featureY = featureY.append(featureXY_series.loc[featureXY_series.index.str.contains(featureY_name)])\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        if len(featureX) == 0:\n",
    "            featureX_mean = np.nan\n",
    "            featureX_min = np.nan\n",
    "        else:\n",
    "            featureX_mean =np.nanmean(featureX)\n",
    "            featureX_min =np.nanmin(featureX)       \n",
    "        if len(featureY) == 0:\n",
    "            featureY_mean = np.nan\n",
    "            featureY_min = np.nan\n",
    "        else:\n",
    "            featureY_mean =np.nanmean(featureY)\n",
    "            featureY_min =np.nanmin(featureY)\n",
    "    return [featureY_mean, featureX_mean,featureY_min,featureX_min]\n",
    "\n",
    "def feature20XY_interference(feature20XY_series):\n",
    "    #返回 feature X/Y _if 两个个值 ， apply函数需要设置result_type = 'expand'\n",
    "    \n",
    "    feature_if_dict = {} # X和Y分别的信号值-干扰值\n",
    "    feature20 = feature20XY_series.loc[feature20XY_series.index.str.contains('feature20')]\n",
    "    featureY_list = ['feature28','feature36','feature44','feature62']\n",
    "    featureX_list = ['feature61','feature69','feature81','feature85']\n",
    "    \n",
    "    for featureV_list in [featureY_list,featureX_list]:\n",
    "        for featureV_name in featureV_list:\n",
    "            featureV = feature20XY_series.loc[feature20XY_series.index.str.contains(featureV_name)]\n",
    "            # 计算得到[[横坐标，纵坐标，V值] *8]\n",
    "            c_v_list = []\n",
    "            for i,value in zip(feature20,featureV):\n",
    "                if not (np.isnan(i) and np.isnan(value)):\n",
    "                        c_v = [i-8*(i//8), i//8, value]\n",
    "                        c_v_list.append(c_v)\n",
    "            interference = 0 #干扰计算公式，Σ(S -Σsn/dn)\n",
    "            for item in c_v_list:\n",
    "                for other_item in c_v_list:\n",
    "                    if other_item != item: \n",
    "                        distance =((item[0]-other_item[0])**2 + (item[1]-other_item[1])**2)**0.5\n",
    "                        if distance == 0: distance = 1 \n",
    "                        interference += other_item[2] / distance\n",
    "            if len(c_v_list) == 0 :\n",
    "                interference = np.nan \n",
    "            else:\n",
    "                interference = interference/len(c_v_list)\n",
    "                interference = round(interference,2)\n",
    "            feature_if_dict[featureV_name] = interference\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        featureY_if = np.nanmean([feature_if_dict[k] for k in featureY_list])\n",
    "        featureX_if = np.nanmean([feature_if_dict[k] for k in featureX_list])\n",
    "    return [featureY_if,featureX_if]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090610ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  label file\n",
    "df_train_label = pd.read_csv(os.path.join(label_path,train_label_file),index_col='sample_index')\n",
    "train_label_dict = df_train_label['root-cause(s)'].to_dict()\n",
    "\n",
    "unknown_label_dict = {}\n",
    "for i in range(2984):\n",
    "    if i not in train_label_dict.keys():\n",
    "        unknown_label_dict[i] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ec89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select feature\n",
    "feature_all = ['feature0', 'feature1', 'feature2', \n",
    "       'feature3_1','feature3_2', 'feature3_3', 'feature3_4', \n",
    "       'feature11', 'feature12', 'feature13','feature14', 'feature15', \n",
    "       'feature16', 'feature17', 'feature18','feature19', 'feature60',\n",
    "       'feature20_distance','feature20_edge',\n",
    "       'featureY_if','featureX_if','featureY_mean','featureX_mean',\n",
    "       'featureY_min','featureX_min'\n",
    "       ]\n",
    "feature_select =  ['feature0', 'feature1', 'feature2',\n",
    "       'feature11', 'feature12','feature13', 'feature14', 'feature15', \n",
    "       'feature16','feature17','feature18', 'feature19', 'feature60',\n",
    "       'feature20_distance','featureY_if','featureX_if','featureY_mean','featureX_mean'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a388407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证数据集维度 (14933, 27) 14933\n",
      "验证数据集维度 (20910, 26) 20910\n"
     ]
    }
   ],
   "source": [
    "# preprocess datatest + feature enginering\n",
    "def load_dataset_for_train(data_path,label_dict): \n",
    "    df_data = pd.DataFrame()\n",
    "    row_num = 0\n",
    "    for sample_index,cause in label_dict.items():\n",
    "        df = pd.read_csv(os.path.join(data_path,str(sample_index)+'.csv'))\n",
    "        row_num += len(df)    \n",
    "        df['feature60'] = df['feature60'].apply(feature60_process)\n",
    "        df['feature20_edge'] = df.loc[:,df.columns.str.contains('feature20')].apply(feature20_edge_count,axis=1)\n",
    "        df['feature20_distance'] = df.loc[:,df.columns.str.contains('feature20')].apply(feature20_distance_count,axis=1)\n",
    "        df[['featureY_if','featureX_if']] = df.apply(feature20XY_interference,axis=1,result_type='expand')\n",
    "        df[['featureY_mean','featureX_mean','featureY_min','featureX_min']] = df.apply(featureXY_process,axis=1,result_type='expand')\n",
    "        tmp = df.loc[:,feature_all]\n",
    "        tmp.insert(0,'causes_type',cause) \n",
    "        tmp.insert(1,'sample_index',sample_index)\n",
    "        df_data = df_data.append(tmp,ignore_index=True)\n",
    "    df_data.dropna(axis=1, inplace=True,how='all') #扔掉所有na的列\n",
    "    print('验证数据集维度',df_data.shape, row_num)\n",
    "    return df_data\n",
    "\n",
    "def load_dataset_for_test(data_path,file_num): \n",
    "    df_data = pd.DataFrame()\n",
    "    row_num = 0\n",
    "    for i in range(file_num):\n",
    "        df = pd.read_csv(os.path.join(data_path,str(i)+'.csv'))\n",
    "        row_num += len(df)    \n",
    "        df['feature60'] = df['feature60'].apply(feature60_process)\n",
    "        df['feature20_edge'] = df.loc[:,df.columns.str.contains('feature20')].apply(feature20_edge_count,axis=1)\n",
    "        df['feature20_distance'] = df.loc[:,df.columns.str.contains('feature20')].apply(feature20_distance_count,axis=1)\n",
    "        df[['featureY_if','featureX_if']] = df.apply(feature20XY_interference,axis=1,result_type='expand')\n",
    "        df[['featureY_mean','featureX_mean','featureY_min','featureX_min']] = df.apply(featureXY_process,axis=1,result_type='expand')\n",
    "        tmp = df.loc[:,feature_all]\n",
    "        tmp.insert(1,'sample_index',i)\n",
    "        df_data = df_data.append(tmp,ignore_index=True)\n",
    "    df_data.dropna(axis=1, inplace=True,how='all') #扔掉所有na的列\n",
    "    print('验证数据集维度',df_data.shape, row_num)\n",
    "    return df_data\n",
    "\n",
    "df_train = load_dataset_for_train(os.path.join(data_path,train_path),train_label_dict)\n",
    "df_test = load_dataset_for_test(os.path.join(data_path,test_path),600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09144498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed data\n",
    "\n",
    "# df_train.to_csv('train_for_ml.csv')\n",
    "# df_test.to_csv('test_for_ml.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
