{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 此notebook使用textcnn方法对根因1进行单独分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 处理好的数据的路径，文件格式为csv，是对原始数据进行填充和截断之后的数据。并且进行了z-score归一化\n",
    "Folder_Path = 'D:/data/rootcausecontest/train/z_score_train/z_score_train' \n",
    "## 模型文件保存姓名\n",
    "model_name= 'D:/data/rootcausecontest/textcnn_with_attention_for_root1.h5'\n",
    "## 标签路径\n",
    "label_path = 'D:/data/rootcausecontest/processed_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import *\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.optimizers import adam_v2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 挑选的特征\n",
    "features = ['feature0', 'feature1', 'feature2', 'feature11', 'feature12','feature13', 'feature15',\n",
    "        'feature16', 'feature17','feature18',\n",
    "        'feature19',\n",
    "        'feature28_0', 'feature28_1', 'feature28_2', 'feature28_3',\n",
    "        'feature28_4', 'feature28_5', 'feature28_6', 'feature28_7',\n",
    "        'feature36_0', 'feature36_1', 'feature36_2', 'feature36_3',\n",
    "        'feature36_4', 'feature36_5', 'feature36_6', 'feature36_7', 'feature60',\n",
    "        'feature61_0', 'feature61_1', 'feature61_2', 'feature61_3',\n",
    "        'feature61_4', 'feature61_5', 'feature61_6', 'feature61_7','feature_edge','feature_distance','length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取数据预处理阶段处理好的label\n",
    "label_all = pd.read_csv(label_path,index_col = 0,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##将标签转换成1，2，3，4，1代表根因1；2代表根因2；3代表根因3；4代表根因2和3一起出现\n",
    "label_list = []\n",
    "for row in label_all.index:\n",
    "    labels = label_all.loc[row,str(1):str(6)] \n",
    "    if (len(np.where(labels>0)[0]))>1:\n",
    "        label_list.append(4)\n",
    "    elif (len(np.where(labels>0)[0]))==1:\n",
    "        label_list.append(np.where(labels>0)[0][0]+1)\n",
    "    else:\n",
    "        label_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all['labels'] = label_list\n",
    "y =label_all['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##将其它标签置0，单独对根因1进行分类\n",
    "y[y == 1] = 1\n",
    "y[y == 2] = 0\n",
    "y[y == 3] = 0\n",
    "y[y == 4] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407\n"
     ]
    }
   ],
   "source": [
    "##此处对特征进行读取和处理\n",
    "import os\n",
    "files = os.listdir(Folder_Path)\n",
    "print(len(files))\n",
    "files.sort(key=lambda x:int(x[:-4]))\n",
    "all_feature = []\n",
    "for filename in files:\n",
    "    df = pd.read_csv(Folder_Path+'/'+filename,index_col = 0)\n",
    "    list_tmp = []\n",
    "    for nd in features:\n",
    "        for i in df[nd].values:\n",
    "            if type(i) == str:\n",
    "                if len(i.split(';'))> 1:\n",
    "                    i = np.array(i.split(';')).astype(float).mean()\n",
    "            list_tmp.append(i)\n",
    "    all_feature.append(list_tmp)\n",
    "all_feature = np.array(all_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##防止有缺失值\n",
    "all_feature[np.isnan(all_feature)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据增强，出来得结果0和1两类标签都一样\n",
    "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(all_feature, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1295), (1, 1295)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "def dataprocess(teature,labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(teature, labels, test_size=0.2) \n",
    "    return x_train,y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_final = X_resampled.reshape(-1,len(features),30)\n",
    "X_train, y_train, X_test, y_test = dataprocess(feature_final,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义注意力模块的函数\n",
    "def attention_3d_block(inputs, time_steps):\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(time_steps, activation='softmax')(a)\n",
    "    if False:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    print(a_probs.shape, inputs.shape)\n",
    "    output_attention_mul = Multiply()([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 39, 30) (None, 39, 30)\n"
     ]
    }
   ],
   "source": [
    "##定义模型，设计模型参数\n",
    "from keras.layers import Input\n",
    "from tensorflow.python.keras import regularizers\n",
    "pool_output = []\n",
    "kernel_sizes = [3, 4, 5]\n",
    "main_input = Input(shape=(X_train.shape[1],30), dtype='float64')\n",
    "O_seq = attention_3d_block(main_input, X_train.shape[1])\n",
    "for kernel_size in kernel_sizes:\n",
    "    c = Conv1D(filters=32, kernel_size=kernel_size, padding='same', strides=1)(O_seq)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = Activation('relu')(c)\n",
    "    p = MaxPooling1D(pool_size=2)(c)\n",
    "    p = Flatten()(p)\n",
    "    pool_output.append(p)\n",
    "x_flatten = concatenate(pool_output)\n",
    "x_flatten = Dropout(0.4)(x_flatten)\n",
    "y = Dense(2,activation ='softmax',kernel_regularizer=regularizers.l1(0.01))(x_flatten)\n",
    "model = Model(inputs=main_input, outputs=y)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train...\n",
      "Epoch 1/300\n",
      "65/65 [==============================] - 2s 10ms/step - loss: 0.9866 - accuracy: 0.9402 - val_loss: 0.9978 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "22/65 [=========>....................] - ETA: 0s - loss: 0.5260 - accuracy: 0.9915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.9899 - val_loss: 0.6133 - val_accuracy: 0.9961 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.2081 - accuracy: 0.9942 - val_loss: 0.4709 - val_accuracy: 0.9923 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.1557 - accuracy: 0.9961 - val_loss: 0.3365 - val_accuracy: 0.9961 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1287 - accuracy: 0.9957 - val_loss: 0.2239 - val_accuracy: 0.9961 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.1125 - accuracy: 0.9981 - val_loss: 0.1639 - val_accuracy: 0.9961 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.1006 - accuracy: 0.9976 - val_loss: 0.1227 - val_accuracy: 0.9961 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9990 - val_loss: 0.0998 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0861 - accuracy: 0.9986 - val_loss: 0.0827 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9990 - val_loss: 0.0760 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9995 - val_loss: 0.0695 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0687 - accuracy: 0.9986 - val_loss: 0.0655 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9990 - val_loss: 0.0612 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9995 - val_loss: 0.0568 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9995 - val_loss: 0.0527 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9995 - val_loss: 0.0533 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9995 - val_loss: 0.0443 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9990 - val_loss: 0.0438 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9995 - val_loss: 0.0427 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9995 - val_loss: 0.0392 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9995 - val_loss: 0.0407 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9995 - val_loss: 0.0371 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9995 - val_loss: 0.0315 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9981 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 61/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 62/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 63/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 64/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 65/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 66/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 67/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 68/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 69/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 70/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 71/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 72/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 73/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 74/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 75/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 76/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 77/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9981 - lr: 5.0000e-04\n",
      "Epoch 78/300\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9961 - lr: 5.0000e-04\n",
      "Epoch 79/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 80/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 81/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 82/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 83/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 84/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 85/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 86/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 87/300\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 88/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 89/300\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9981 - lr: 2.5000e-04\n",
      "Epoch 90/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 91/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 92/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9995 - val_loss: 0.0203 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 93/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 94/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 95/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 96/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 97/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 98/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 99/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 100/300\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9981 - lr: 1.2500e-04\n",
      "Epoch 101/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 102/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 103/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 104/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 105/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 106/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 107/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 108/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 109/300\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9981 - lr: 6.2500e-05\n",
      "Epoch 110/300\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 111/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 112/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 113/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 114/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 115/300\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 116/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 117/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 118/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 119/300\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 120/300\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "\n",
      "Testing...\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9981\n",
      "Test loss:   0.018833903595805168\n",
      "Test accuracy:   0.9980695247650146\n"
     ]
    }
   ],
   "source": [
    "##训练模型，生成模型文件\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "Reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5,\n",
    "                           mode='auto', cooldown=0, min_lr=0.000001, verbose = 1)\n",
    "opt = adam_v2.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "    ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True),\n",
    "    Reduce\n",
    "]\n",
    "print('\\nTrain...')\n",
    "one_hot_labels = to_categorical(y_train, num_classes=2) \n",
    "one_hot_labels_test = to_categorical(y_test, num_classes=2) \n",
    "history = model.fit(x = X_train, y = one_hot_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=300,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, one_hot_labels_test),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "print(\"\\nTesting...\")\n",
    "model = load_model(model_name)\n",
    "score, accuracy = model.evaluate(X_test, one_hot_labels_test,\n",
    "                                 batch_size=64,\n",
    "                                 verbose=1)\n",
    "print(\"Test loss:  \", score)\n",
    "print(\"Test accuracy:  \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下部分为读取模型生成根因1的csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##原始测试数据文件\n",
    "Folder_Path1 = 'D:/data/rootcausecontest/test_600'\n",
    "##处理过后的测试集文件，每个文件30行\n",
    "Folder_Path2 = 'D:/data/rootcausecontest/test/z_score_test/z_score_test' \n",
    "model_name_test = 'D:/data/rootcausecontest/textcnn_with_attention_for_root1_old.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 此处用来统计feature13和feature15的均值，基于我们的发现，\n",
    "##这两个特征波动比较大的文件大多包含多个根因\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "feature13_std = []\n",
    "feature15_std = []\n",
    "files = os.listdir(Folder_Path1)\n",
    "files.sort(key=lambda x:int(x[:-4]))\n",
    "for filename in files:\n",
    "    df = pd.read_csv(Folder_Path1+'/'+filename,index_col = 0)\n",
    "    feature13_std.append(df['feature13'].std())\n",
    "    feature15_std.append(df['feature15'].std())\n",
    "feature13_std = np.array(feature13_std)\n",
    "feature15_std = np.array(feature15_std)\n",
    "feature13_std[np.isnan(feature13_std)] = 0\n",
    "feature15_std[np.isnan(feature15_std)] = 0\n",
    "feature13_std = feature13_std/np.max(feature13_std)\n",
    "feature15_std = feature15_std/np.max(feature15_std)\n",
    "feature_fil = feature13_std+feature15_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###此cell用来读取600个文件的特征参数，出来list的维度是[600,len(nodes)*20]\n",
    "import os\n",
    "import pandas as pd\n",
    "files = os.listdir(Folder_Path2)\n",
    "files.sort(key=lambda x:int(x[:-4]))\n",
    "all_feature = []\n",
    "for filename in files:\n",
    "    df = pd.read_csv(Folder_Path2+'/'+filename,index_col = 0)\n",
    "    list_tmp = []\n",
    "    for nd in features:\n",
    "        for i in df[nd].values:\n",
    "            if type(i) == str:\n",
    "                if len(i.split(';'))> 1:\n",
    "                    i = np.array(i.split(';')).astype(float).mean()\n",
    "            list_tmp.append(i)\n",
    "    all_feature.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这边reshape了一下，往模型里面送模型接收的维度是[600,len(nodes),20]\n",
    "all_feature = np.array(all_feature).reshape(-1,len(features),30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取模型\n",
    "from keras.models import load_model\n",
    "model = load_model(model_name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行预测\n",
    "res = model.predict(all_feature)\n",
    "result = np.argmax(res,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##由于存在根因1和多种其它根因出现的情况，降低根因1的判别阈值\n",
    "result_new = []\n",
    "for i in res:\n",
    "    if i[0]>0.8:\n",
    "        result_new.append(0)\n",
    "    else:\n",
    "        result_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#形成最后提交的csv\n",
    "submit = np.zeros((600,6))\n",
    "for i in range(len(result_new)):\n",
    "    if result_new[i] == 1:\n",
    "        submit[i,0] = 1\n",
    "submit_dataframe = pd.DataFrame()\n",
    "submit_dataframe['ID'] = [i for i in range(600)]\n",
    "for i in range(len(submit[0])):\n",
    "    col = 'Root cause {}'.format(i+1)\n",
    "    submit_dataframe[col] = submit[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 单独对每行进行预测\n",
    "pre_result = pd.DataFrame(columns=['index','length','pre=1','pre=0','score'])\n",
    "for m in range(600):\n",
    "    test_array = []\n",
    "    raw = pd.read_csv(Folder_Path2 + '/{}.csv'.format(m),index_col=0)\n",
    "    raw = raw[features]\n",
    "    for i in range(len(raw)):\n",
    "        line = raw.loc[i,:].to_frame().T\n",
    "        line_30 = pd.DataFrame(np.repeat(line.values,30,axis=0))\n",
    "        line_30.columns = line.columns\n",
    "        test_array.append(line_30.T.values)\n",
    "    test_array = np.array(test_array)\n",
    "    res2 = model.predict(test_array)\n",
    "    result2 = np.argmax(res2,axis=1)\n",
    "    t = []\n",
    "    t.append(m)\n",
    "    t.append(len(result2))\n",
    "    t.append(result2.sum())\n",
    "    t.append(len(result2)-result2.sum())\n",
    "    t.append(res2[:,1].sum()/len(result2))\n",
    "    pre_result.loc[m,:]=t\n",
    "pre_result.to_csv('D:/data/rootcausecontest/pre_result_soft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##处理较慢，此处有之前的运行结果\n",
    "pre_result = pd.read_csv('D:/data/rootcausecontest/pre_result.csv') ##硬判决文件\n",
    "pre_result['score'] = pre_result['pre=1']/pre_result['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##若用软判决则关闭上面两行代码\n",
    "# pre_result = pd.read_csv('D:/data/rootcausecontest/pre_result_new.csv') ##软判决文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##软判决门限\n",
    "# add_1 = []\n",
    "# for i in range(len(pre_result['score'])):\n",
    "#     if pre_result['score'][i] == 1:\n",
    "#         add_1.append(i)\n",
    "# for val in np.where(np.array(feature_fil)>0.6)[0]:  ## 用于筛选特征13和15波动性比较大的样本\n",
    "#     if pre_result.loc[val,'score']>0.14:\n",
    "#         add_1.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##硬判决门限\n",
    "add_1 = []\n",
    "for i in range(len(pre_result['score'])):\n",
    "    if pre_result['score'][i] == 1:\n",
    "        add_1.append(i)\n",
    "for val in np.where(np.array(feature_fil)>0.6)[0]:  ## 用于筛选特征13和15波动性比较大的样本\n",
    "    if pre_result.loc[val,'score']>0.2:\n",
    "        add_1.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_dataframe.loc[add_1,'Root cause 1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_dataframe.to_csv('D:/data/rootcausecontest/submit_root1.csv',index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
